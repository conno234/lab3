{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import requests\n",
    "from shapely.wkb import loads as wkb_loads\n",
    "import requests\n",
    "import csv\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from osgeo import gdal\n",
    "import geopandas\n",
    "import pyproj\n",
    "import random\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Portions of this notebook were developed using AI generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will connect to the original database\n",
    "db_params = {\n",
    "    'database': 'lab1.2',  \n",
    "    'user': '(USER)',  \n",
    "    'password': '(PASSWORD), \n",
    "    'host': '(HOST)', \n",
    "    'port': '5432' \n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**db_params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Then  we will select the needed table\n",
    "sql_query = \"SELECT grid_code, wkt_geom FROM minn_elevation_wkt\"\n",
    "cursor.execute(sql_query)\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# Then convert fetched data to a dataframe\n",
    "elevation_df = pd.DataFrame(data, columns=['grid_code', 'wkt_geom'])\n",
    "\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_properties = {\n",
    "    'database': 'lab3',\n",
    "    'user': '(USER)',  \n",
    "    'password': '(PASSWORD), \n",
    "    'host': '(HOST)',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "\n",
    "db_connection_file = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Lab 2\\database_connection.sde\"\n",
    "arcpy.CreateDatabaseConnection_management(out_folder_path=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Lab 2\",\n",
    "                                          out_name=\"database_connection\",\n",
    "                                          database_platform=\"POSTGRESQL\",\n",
    "                                          instance=connection_properties['host'],\n",
    "                                          account_authentication=\"DATABASE_AUTH\",\n",
    "                                          username=connection_properties['user'],\n",
    "                                          password=connection_properties['password'],\n",
    "                                          save_user_pass=\"SAVE_USERNAME\",\n",
    "                                          database=connection_properties['database'],\n",
    "                                          version_type=\"TRANSACTIONAL\",\n",
    "                                          version=\"dbo.DEFAULT\"\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will then create our elevation feature class\n",
    "output_fc = \"Elevation_Data\"\n",
    "\n",
    "# We will define the spatial reference for UTM Zone 15N and our desired deature class\n",
    "utm_spatial_reference = arcpy.SpatialReference(32615)\n",
    "wgs84_spatial_reference = arcpy.SpatialReference(4326)  # EPSG code for WGS84\n",
    "\n",
    "\n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, output_fc, \"POINT\", spatial_reference=wgs84_spatial_reference)\n",
    "arcpy.management.AddField(output_fc, \"grid_code\", \"FLOAT\")\n",
    "\n",
    "# Then we iterate over each row in the elevation dataframe\n",
    "with arcpy.da.InsertCursor(output_fc, [\"SHAPE@\", \"grid_code\"]) as cursor:\n",
    "    for index, row in elevation_df.iterrows():\n",
    "        wkt_geom = row['wkt_geom']\n",
    "        grid_code = row['grid_code']\n",
    "        x, y = map(float, wkt_geom[7:-1].split())\n",
    "        \n",
    "        # Then we can create point geometry from X and Y coordinates\n",
    "        point = arcpy.Point(x, y)\n",
    "        geom = arcpy.PointGeometry(point, utm_spatial_reference)\n",
    "        \n",
    "        # We then project point geometry to WGS84 (latitude and longitude)\n",
    "        projected_geom = geom.projectAs(wgs84_spatial_reference)\n",
    "        \n",
    "        # Then we insert each row into the feature class\n",
    "        cursor.insertRow((projected_geom, grid_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, April 12, 2024 9:08:39 PM\",\"Succeeded at Friday, April 12, 2024 9:08:53 PM (Elapsed Time: 13.90 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\Lab 3 v2\\\\Lab 3 v2.gdb\\\\Sampled_Elevation_Data'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next we need to sample the larger raster data\n",
    "input_feature_layer = \"Elevation_Data\"\n",
    "output_feature_layer = \"Sampled_Elevation_Data\"\n",
    "\n",
    "total_features = int(arcpy.GetCount_management(input_feature_layer).getOutput(0))\n",
    "\n",
    "# We will select 1000 indices without replacement\n",
    "sample_indices = random.sample(range(total_features), 1000)\n",
    "\n",
    "# Then we will create a SQL query to select the sampled features\n",
    "sql_query = f\"OBJECTID IN ({', '.join(map(str, sample_indices))})\"\n",
    "\n",
    "# We can then create the output feature layer with sampled features\n",
    "arcpy.management.SelectLayerByAttribute(input_feature_layer, \"NEW_SELECTION\", sql_query)\n",
    "arcpy.management.CopyFeatures(input_feature_layer, output_feature_layer)\n",
    "\n",
    "print(\"Sample data collected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to test our interpolations later, we will need to create another subset of this data and remove it from the feature layer\n",
    "input_feature_layer = \"Sampled_Elevation_Data\"\n",
    "\n",
    "# We will save it as a separate feature layer\n",
    "output_feature_layer = \"Random_Selected_Elevation_Features\"\n",
    "output_feature_class = \"Random_Selected_Elevation_Features_Class\"\n",
    "\n",
    "# We first need to get the total count of features in the input feature layer\n",
    "total_features_count = int(arcpy.GetCount_management(input_feature_layer).getOutput(0))\n",
    "\n",
    "# Then I will generate a list of 100 random indices\n",
    "random_indices = random.sample(range(1, total_features_count + 1), 100)\n",
    "\n",
    "# I will use a SQL expression to select the randomly chosen features\n",
    "sql_expression = \"OBJECTID IN ({})\".format(','.join(map(str, random_indices)))\n",
    "\n",
    "# Then I will create a new feature layer with the randomly selected features\n",
    "arcpy.MakeFeatureLayer_management(input_feature_layer, output_feature_layer, sql_expression)\n",
    "\n",
    "print(\"Randomly selected 100 features and created a new feature layer:\", output_feature_layer)\n",
    "\n",
    "# The I will save the selected features to a new feature class\n",
    "arcpy.CopyFeatures_management(output_feature_layer, output_feature_class)\n",
    "print(\"Saved the selected features to a new feature class:\", output_feature_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then I will go through and conduct my interpolations\n",
    "#First is IDW\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\"):\n",
    "    Idw_elev = arcpy.sa.Idw(\n",
    "        in_point_features=\"Sampled_Elevation_Data\",\n",
    "        z_field=\"grid_code\",\n",
    "        cell_size=2160,\n",
    "        power=2,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        in_barrier_polyline_features=None\n",
    "    )\n",
    "    Idw_elev.save(r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Idw_Elev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then splining\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\"):\n",
    "    Spline_elev = arcpy.sa.Spline(\n",
    "        in_point_features=\"Sampled_Elevation_Data\",\n",
    "        z_field=\"grid_code\",\n",
    "        cell_size=2160,\n",
    "        spline_type=\"REGULARIZED\",\n",
    "        weight=0.1,\n",
    "        number_points=12\n",
    "    )\n",
    "    Spline_elev.save(r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Spline_elev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then kriging\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\"):\n",
    "    Kriging_elev = arcpy.sa.Kriging(\n",
    "        in_point_features=\"Sampled_Elevation_Data\",\n",
    "        z_field=\"grid_code\",\n",
    "        kriging_model=\"Spherical 2160.000000 # # #\",\n",
    "        cell_size=2160,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        out_variance_prediction_raster=None\n",
    "    )\n",
    "    Kriging_elev.save(r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Kriging_elev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The interpolations need to be saved in our PostGIS database. As they are rasters, I will first resample them to cut down on file size\n",
    "\n",
    "arcpy.management.Resample(\n",
    "    in_raster=\"Idw_elev\",\n",
    "    out_raster=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Idw_Elev_Resample\",\n",
    "    cell_size=\"0.1 0.1\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "arcpy.management.Resample(\n",
    "    in_raster=\"Kriging_elev\",\n",
    "    out_raster=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Kriging_Elev_Resample\",\n",
    "    cell_size=\"0.1 0.1\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "arcpy.management.Resample(\n",
    "    in_raster=\"Spline_elev\",\n",
    "    out_raster=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Spline_Elev_Resample\",\n",
    "    cell_size=\"0.1 0.1\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "print(\"Resampling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, April 12, 2024 9:15:41 PM\",\"WARNING 010151: No features created by operation.\",\"Succeeded at Friday, April 12, 2024 9:16:13 PM (Elapsed Time: 31.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\Lab 3 v2\\\\Lab 3 v2.gdb\\\\Idw_Elev_Point'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we will convert these rasters to points for easier storage\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Spline_Elev_Resample\",\n",
    "    out_point_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Spline_Elev_Point\",\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Kriging_Elev_Resample\",\n",
    "    out_point_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Kriging_Elev_Point\",\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Idw_Elev_Resample\",\n",
    "    out_point_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Idw_Elev_Point\",\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "print(\"Raster to Point complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, April 12, 2024 11:35:11 PM\",\"Succeeded at Friday, April 12, 2024 11:39:30 PM (Elapsed Time: 4 minutes 18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\Lab 3 v2\\\\PostgreSQL-34-lab3(postgres).sde\\\\lab3.postgres.Kriging_elev_point'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will then save these layers to our PostGIS database\n",
    "arcpy.conversion.ExportFeatures('Kriging_Elev_Point',r'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde\\lab3.postgres.Kriging_elev_point')\n",
    "\n",
    "arcpy.conversion.ExportFeatures('Idw_Elev_Point',r'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde\\lab3.postgres.Idw_elev_point')\n",
    "\n",
    "arcpy.conversion.ExportFeatures('Spline_Elev_Point',r'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde\\lab3.postgres.Spline_elev_point')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling complete\n"
     ]
    }
   ],
   "source": [
    "# Then we will perform our interpolation accuracy assessment\n",
    "# To begin, we will use the rendomly generated points to sample our interpolations\n",
    "arcpy.sa.Sample(\n",
    "    in_rasters=\"Idw_elev\",\n",
    "    in_location_data=\"Random_Selected_Elevation_Features\",\n",
    "    out_table=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Sample_Idw_Elev\",\n",
    "    resampling_type=\"NEAREST\",\n",
    "    unique_id_field=\"OBJECTID\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    acquisition_definition=None,\n",
    "    statistics_type=\"\",\n",
    "    percentile_value=None,\n",
    "    buffer_distance=None,\n",
    "    layout=\"ROW_WISE\",\n",
    "    generate_feature_class=\"TABLE\"\n",
    ")\n",
    "print(\"Sampling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.sa.Sample(\n",
    "    in_rasters=\"Spline_elev\",\n",
    "    in_location_data=\"Random_Selected_Elevation_Features\",\n",
    "    out_table=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Sample_Spline_Elev\",\n",
    "    resampling_type=\"NEAREST\",\n",
    "    unique_id_field=\"OBJECTID\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    acquisition_definition=None,\n",
    "    statistics_type=\"\",\n",
    "    percentile_value=None,\n",
    "    buffer_distance=None,\n",
    "    layout=\"ROW_WISE\",\n",
    "    generate_feature_class=\"TABLE\"\n",
    ")\n",
    "print(\"Sampling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.sa.Sample(\n",
    "    in_rasters=\"Kriging_elev\",\n",
    "    in_location_data=\"Random_Selected_Elevation_Features\",\n",
    "    out_table=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\Lab 3 v2.gdb\\Sample_Kriging_Elev\",\n",
    "    resampling_type=\"NEAREST\",\n",
    "    unique_id_field=\"OBJECTID\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    acquisition_definition=None,\n",
    "    statistics_type=\"\",\n",
    "    percentile_value=None,\n",
    "    buffer_distance=None,\n",
    "    layout=\"ROW_WISE\",\n",
    "    generate_feature_class=\"TABLE\"\n",
    ")\n",
    "print(\"Sampling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OBJECTID  grid_code     SHAPE@X     SHAPE@Y\n",
      "0          4     1060.0  357275.332  5444935.37\n",
      "1         16     1065.0  352275.332  5424935.37\n",
      "2         37      980.0  232275.332  5394935.37\n",
      "3         53     1268.0  347275.332  5379935.37\n",
      "4         69     1055.0  242275.332  5364935.37\n",
      "..       ...        ...         ...         ...\n",
      "95       908     1096.0  532275.332  4869935.37\n",
      "96       915     1283.0  492275.332  4864935.37\n",
      "97       918     1197.0  552275.332  4864935.37\n",
      "98       940     1099.0  572275.332  4854935.37\n",
      "99       950     1642.0  227275.332  4844935.37\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the input feature class\n",
    "input_feature_class = \"Random_Selected_Elevation_Features\"\n",
    "\n",
    "# Convert feature class to NumPy array\n",
    "fields = ['OID@', \"grid_code\", \"SHAPE@X\", \"SHAPE@Y\"]\n",
    "array = arcpy.da.FeatureClassToNumPyArray(input_feature_class, fields)\n",
    "\n",
    "# Convert NumPy array to DataFrame\n",
    "df_original = pd.DataFrame(array)\n",
    "\n",
    "# Rename the OID@ field to ObjectID\n",
    "df_original.rename(columns={\"OID@\": \"OBJECTID\"}, inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will then create individual dataframes for the interpolations\n",
    "table_paths = [\n",
    "    \"Sample_Idw_Elev\",\n",
    "    \"Sample_Kriging_Elev\",\n",
    "    \"Sample_Spline_Elev\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for table_path in table_paths:\n",
    "    array = arcpy.da.TableToNumPyArray(table_path, \"*\")\n",
    "    df = pd.DataFrame(array)\n",
    "    dfs.append(df)\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"DataFrame {i+1} ({table_paths[i]}):\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will then join the dataframes\n",
    "dfs_to_join = [\n",
    "    df_original,  # Temperature_Data DataFrame\n",
    "    dfs[0],  # Sample_Idw_Temp DataFrame\n",
    "    dfs[1],  # Sample_Kriging_Temp DataFrame\n",
    "    dfs[2]   # Sample_Spline_Temp DataFrame\n",
    "]\n",
    "\n",
    "suffixes = ['_original', '_idw', '_kriging', '_spline']\n",
    "for i, df_to_join in enumerate(dfs_to_join[1:], start=1):\n",
    "    df_original = df_original.merge(df_to_join, how='left', left_on='OBJECTID', right_on='OBJECTID', suffixes=('', suffixes[i]))\n",
    "\n",
    "# Print the joined DataFrame\n",
    "print(df_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['Idw_Elev_Band_1_difference'] = df_original['grid_code'] - df_original['Idw_Elev_Band_1']\n",
    "df_original['Spline_Elev_Band_1_difference'] = df_original['grid_code'] - df_original['Spline_elev_Band_1']\n",
    "df_original['Kriging_Elev_Band_1_difference'] = df_original['grid_code'] - df_original['Kriging_elev_Band_1']\n",
    "\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we calculate mean for each method\n",
    "idw_mean = df_original['Idw_Elev_Band_1_difference'].mean()\n",
    "spline_mean = df_original['Spline_Elev_Band_1_difference'].mean()\n",
    "kriging_mean = df_original['Kriging_Elev_Band_1_difference'].mean()\n",
    "\n",
    "# Then use that to caluclate RMSE for each method\n",
    "idw_rmse = np.sqrt(np.mean(df_original['Idw_Elev_Band_1_difference']**2))\n",
    "spline_rmse = np.sqrt(np.mean(df_original['Spline_Elev_Band_1_difference']**2))\n",
    "kriging_rmse = np.sqrt(np.mean(df_original['Kriging_Elev_Band_1_difference']**2))\n",
    "\n",
    "# Then we create a dictionary to hold the results\n",
    "accuracy_results = {\n",
    "    'Method': ['IDW', 'Spline', 'Kriging'],\n",
    "    'Mean': [idw_mean, spline_mean, kriging_mean],\n",
    "    'RMSE': [idw_rmse, spline_rmse, kriging_rmse]\n",
    "}\n",
    "\n",
    "# We save the data into a dataframe from the dictionary\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DataFrame saved to: C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\accuracy_elevation.csv\n"
     ]
    }
   ],
   "source": [
    "# Then we define the path to save the table\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\accuracy_elevation.csv\"\n",
    "\n",
    "# Finally we save the accuracy dataframe to a CSV file\n",
    "accuracy_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Accuracy DataFrame saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'accuracy_elevation' saved to SDE connection 'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde'.\n"
     ]
    }
   ],
   "source": [
    "#Then we save the CSV to our database\n",
    "sde_connection = r'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde'\n",
    "output_table = \"accuracy_elevation\"\n",
    "csv_file = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\accuracy_elevation.csv\"\n",
    "arcpy.TableToTable_conversion(csv_file, sde_connection, output_table)\n",
    "\n",
    "print(f\"Table '{output_table}' saved to SDE connection '{sde_connection}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will convert the sampling differences into a point feature\n",
    "# Let us start with IDW\n",
    "data_array = df_original[['SHAPE@X', 'SHAPE@Y', 'Idw_Elev_Band_1_difference']].to_numpy()\n",
    "spatial_reference = arcpy.SpatialReference(4326)  # WGS 1984\n",
    "feature_class_name = \"Idw_Difference_Point_Elev\"\n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, feature_class_name, \"POINT\", spatial_reference=spatial_reference)\n",
    "arcpy.management.AddField(feature_class_name, \"Idw_Elev_Band_1_difference\", \"DOUBLE\")\n",
    "with arcpy.da.InsertCursor(feature_class_name, ['SHAPE@X', 'SHAPE@Y', 'Idw_Temper_Band_1_difference']) as cursor:\n",
    "    for row in data_array:\n",
    "        cursor.insertRow(row)\n",
    "\n",
    "print(\"Point feature class created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then Kriging\n",
    "data_array = df_original[['SHAPE@X', 'SHAPE@Y', 'Kriging_Elev_Band_1_difference']].to_numpy()\n",
    "spatial_reference = arcpy.SpatialReference(4326)\n",
    "feature_class_name = \"Kriging_Difference_Point_Elev\"\n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, feature_class_name, \"POINT\", spatial_reference=spatial_reference)\n",
    "arcpy.management.AddField(feature_class_name, \"Kriging_Elev_Band_1_difference\", \"DOUBLE\")\n",
    "with arcpy.da.InsertCursor(feature_class_name, ['SHAPE@X', 'SHAPE@Y', 'Kriging_Temper_Band_1_difference']) as cursor:\n",
    "    for row in data_array:\n",
    "        cursor.insertRow(row)\n",
    "\n",
    "print(\"Point feature class created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then splining\n",
    "data_array = df_original[['SHAPE@X', 'SHAPE@Y', 'Spline_Elev_Band_1_difference']].to_numpy()\n",
    "spatial_reference = arcpy.SpatialReference(4326)  # WGS 1984\n",
    "feature_class_name = \"Spline_Difference_Point_Elev\"\n",
    "arcpy.management.CreateFeatureclass(arcpy.env.workspace, feature_class_name, \"POINT\", spatial_reference=spatial_reference)\n",
    "arcpy.management.AddField(feature_class_name, \"Spline_Elev_Band_1_difference\", \"DOUBLE\")\n",
    "with arcpy.da.InsertCursor(feature_class_name, ['SHAPE@X', 'SHAPE@Y', 'Spline_Temper_Band_1_difference']) as cursor:\n",
    "    for row in data_array:\n",
    "        cursor.insertRow(row)\n",
    "\n",
    "print(\"Point feature class created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, April 12, 2024 8:43:26 PM\",\"Succeeded at Friday, April 12, 2024 8:44:26 PM (Elapsed Time: 1 minutes 0 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\Lab 3 v2\\\\PostgreSQL-34-lab3(postgres).sde\\\\lab3.postgres.Kriging_Differ_Elev'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, we will save the Kriging difference point layer to our PostGIS database\n",
    "arcpy.conversion.ExportFeatures('Kriging_Difference_Point_Elev',r'C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab 3 v2\\PostgreSQL-34-lab3(postgres).sde\\lab3.postgres.Kriging_Differ_Elev')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
